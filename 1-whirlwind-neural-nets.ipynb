{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building our Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last lesson, we saw some of the data that neural networks could interpret, and explored our Fashion dataset.  In this lesson, we'll work with that dataset again, this time feeding it into a neural network, and then using the neural network to identify some images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we'll need to download our data, which we can do so with the following line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then let's make sure we still have some articles of clothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1693fca60>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And our first label is the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's take a look at what these numbers correspond to make sure this makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist_labels = [\"T-shirt/top\",  # index 0\n",
    "                        \"Trouser\",      # index 1\n",
    "                        \"Pullover\",     # index 2 \n",
    "                        \"Dress\",        # index 3 \n",
    "                        \"Coat\",         # index 4\n",
    "                        \"Sandal\",       # index 5\n",
    "                        \"Shirt\",        # index 6 \n",
    "                        \"Sneaker\",      # index 7 \n",
    "                        \"Bag\",          # index 8 \n",
    "                        \"Ankle boot\"]   # index 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, cool so far so good.  Let's move onto building our neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building our Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build our neural network, we'll use the Pytorch library.  There's no way we can understand the ins and outs of a neural network just in this lesson.  Instead, let's just see it action for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by importing the Pytorch library, and then can build a neural network class with the following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Press `shift + return` on the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(0)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.W1 = nn.Linear(28*28, 64)\n",
    "        self.W2 = nn.Linear(64, 64)\n",
    "        self.W3 = nn.Linear(64, 64)\n",
    "        self.W4 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        A1 = torch.sigmoid(self.W1(X))\n",
    "        A2 = torch.sigmoid(self.W2(A1))\n",
    "        A3 = torch.sigmoid(self.W3(A2))\n",
    "        Z4 = self.W4(A3)\n",
    "        return Z4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So above, we defined a *class* that creates neural networks.  A **class** is a programming concept.  If you're not familiar with term, just know that in the lines above we essentially created a factory that now can produce neural networks for us.  Want to build a neural network?  We just need to call on our factory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (W1): Linear(in_features=784, out_features=64, bias=True)\n",
       "  (W2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (W3): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (W4): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so now that we created our class for building neural networks, and created a neural network itself, let's start training the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Prediction Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now remember that *training* our neural network means that we'll feed our neural network our input data, and the corresponding labels.  This should make sense.  When we called `net = Net()`, we just built a neural network fresh out of the factory.  So while it has the capacity to learn how to identify images -- it hasn't undergone it's training process yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we fed it a picture, it would just make a wild prediction as to what that actual image was.  Let's see that.\n",
    "\n",
    "Ok, now before we feed our training data into the neural network, we'll first need change it up a little.  Currently, our training data is a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need to convert this into Pytorch's equivalent data structure, and make sure that every item is a float.\n",
    "\n",
    "> We do so with the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we'll need to select our first image, and change it from a grid of 28x28 pixels into one long list of $28*28=784$ pixels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_obs = X_train_tensor[0].view(-1, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll discuss the `view` function in more detail later on.  But notice that our first observation has been changed to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_obs[0][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 784])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_obs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now we also will need to convert the labels in the `y_train` variable from an array to a tensor, and to a `long` datatype (which is essentially an integer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tensor = torch.tensor(y_train).long().view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, and we can make a prediction with that first observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0601, -0.1083,  0.1887,  0.3067,  0.5202,  0.0994, -0.5060,  0.0025,\n",
       "          0.1033,  0.1399]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = net(first_obs)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now let's spend some more time interpreting the prediction above.  It may be difficult to understand how the list of numbers above is somehow our neural network predicting what article of clothing was passed through.  What's happening is our neural net is returning 10 numbers one for each of the different fashion labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion_mnist_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It returns 10 different numbers to indicate the likelihood that the photo matches any particular label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0852, 0.0812, 0.1092, 0.1229, 0.1522, 0.0999, 0.0545, 0.0907, 0.1003,\n",
       "         0.1040]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(pred, dim = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So above, our neural network is saying that there is roughly a $8.5%$ likelihood of the picture being a T-shirt, an $8.1%$ likelihood of being a trouser, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to what the neural network thinks is most likely, it's simply the index of with the largest number.  We can get pytorch to tell us which value this is, like so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that our neural network predicts that the first image is what's at image 4 -- or a coat.  In future lessons, we'll better understand this prediction function.  For now, let's move onto training the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we just made a prediction as to what an image is, with an untrained neural network -- that is, a neural network which has not seen a bunch of images and the corresponding labels.  Now it's time to see how our neural network does when we train it.\n",
    "\n",
    "Now in training we'll do the following.  We'll take our set of images, and for each image, we'll input it into our neural network, have the neural network make a prediction, and then update the neural network based on how off the prediction was.  So if the neural network said there was a $.05$ percent chance of the picture being a hat, but the picture was in fact a hat -- the neural network will be updated a lot, and if it predicted a $.95$ percent chance of our hat being a hat, then we would not update our neural network so much.\n",
    "\n",
    "What does it mean to update a neural network?  Well let's take a look at our neural network again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (W1): Linear(in_features=784, out_features=64, bias=True)\n",
       "  (W2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (W3): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (W4): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each one of those `W's` represents a grid of numbers.  Let's see one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              Parameter containing:\n",
       "              tensor([[ 0.0259, -0.0138, -0.0259,  ..., -0.0757, -0.0621, -0.0298],\n",
       "                      [ 0.1063,  0.0534, -0.0855,  ..., -0.0165, -0.0313, -0.0833],\n",
       "                      [ 0.1078,  0.0445,  0.0239,  ..., -0.0503,  0.0975, -0.0178],\n",
       "                      ...,\n",
       "                      [ 0.1124,  0.0989, -0.0902,  ..., -0.0939, -0.0652,  0.1107],\n",
       "                      [ 0.1120, -0.0405,  0.0659,  ..., -0.0038, -0.0218, -0.0882],\n",
       "                      [ 0.1226,  0.0628, -0.0597,  ..., -0.0875,  0.0712,  0.1169]],\n",
       "                     requires_grad=True)),\n",
       "             ('bias',\n",
       "              Parameter containing:\n",
       "              tensor([-0.0495,  0.0637, -0.1004, -0.0250, -0.0909,  0.1096,  0.0405,  0.0485,\n",
       "                       0.0361, -0.1112,  0.0071,  0.0476,  0.1005,  0.0198, -0.0114,  0.0470,\n",
       "                      -0.0566, -0.0448,  0.0945, -0.0279, -0.0823,  0.1084,  0.1233,  0.1245,\n",
       "                      -0.0628, -0.1026,  0.0119,  0.1122, -0.1189,  0.1191, -0.0267, -0.0029,\n",
       "                      -0.0684,  0.0300, -0.0023, -0.0248,  0.0255,  0.0204,  0.0377, -0.0720,\n",
       "                       0.1083,  0.1226,  0.1195, -0.0623,  0.1184, -0.0169,  0.0962,  0.0845,\n",
       "                       0.0651, -0.1006, -0.0409,  0.0330, -0.0726, -0.0220,  0.0756, -0.1135,\n",
       "                       0.0116,  0.0716, -0.1130, -0.0081, -0.0813, -0.0165,  0.1023, -0.0797],\n",
       "                     requires_grad=True))])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.W3._parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of numbers.  \n",
    "\n",
    "> And remember, these are just the numbers that consist of one of those `W's`.  There are four of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on how far off the neural network's ultimate prediction is, those numbers will be updated with each prediction the neural network sees.  \n",
    "\n",
    "It takes a little bit of setup to go through this, but still let's see it in action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We use something called cross entropy loss, and an optimizer -- both oof which we'll learn more about later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_loss = nn.CrossEntropyLoss()\n",
    "x_loss\n",
    "# CrossEntropyLoss()\n",
    "\n",
    "import torch.optim as optim\n",
    "adam = optim.Adam(net.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then if we pass through the neural network's *prediction*, and the corresponding label, we can see how far off we were."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2632, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = net(first_obs)\n",
    "pred\n",
    "\n",
    "first_label = y_train_tensor[0]\n",
    "first_label\n",
    "\n",
    "loss = x_loss(pred, first_label)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can calculate how to update our neural network, and finally, make the update with the `step` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()\n",
    "adam.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that our neural network has been updated, just a little bit, based on it's poor prediction of the first image.  Let's see this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Notice that the first number was updated from $.0259$ to $.03$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              Parameter containing:\n",
       "              tensor([[ 0.0309, -0.0088, -0.0209,  ..., -0.0707, -0.0571, -0.0248],\n",
       "                      [ 0.1013,  0.0484, -0.0905,  ..., -0.0215, -0.0363, -0.0883],\n",
       "                      [ 0.1128,  0.0495,  0.0289,  ..., -0.0453,  0.1025, -0.0128],\n",
       "                      ...,\n",
       "                      [ 0.1174,  0.1039, -0.0852,  ..., -0.0889, -0.0602,  0.1157],\n",
       "                      [ 0.1170, -0.0355,  0.0709,  ...,  0.0012, -0.0168, -0.0832],\n",
       "                      [ 0.1276,  0.0678, -0.0547,  ..., -0.0825,  0.0762,  0.1219]],\n",
       "                     requires_grad=True)),\n",
       "             ('bias',\n",
       "              Parameter containing:\n",
       "              tensor([-0.0445,  0.0587, -0.0954, -0.0200, -0.0859,  0.1046,  0.0355,  0.0435,\n",
       "                       0.0411, -0.1062,  0.0021,  0.0426,  0.1055,  0.0148, -0.0164,  0.0420,\n",
       "                      -0.0616, -0.0398,  0.0995, -0.0329, -0.0773,  0.1134,  0.1283,  0.1295,\n",
       "                      -0.0678, -0.1076,  0.0169,  0.1072, -0.1239,  0.1241, -0.0217,  0.0021,\n",
       "                      -0.0634,  0.0350, -0.0073, -0.0298,  0.0205,  0.0154,  0.0427, -0.0670,\n",
       "                       0.1133,  0.1176,  0.1145, -0.0673,  0.1134, -0.0219,  0.0912,  0.0895,\n",
       "                       0.0701, -0.0956, -0.0459,  0.0380, -0.0676, -0.0270,  0.0806, -0.1185,\n",
       "                       0.0166,  0.0666, -0.1080, -0.0131, -0.0863, -0.0115,  0.1073, -0.0747],\n",
       "                     requires_grad=True))])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.W3._parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so now we just loop through all of our images, and for each one, ask our neural network to make a prediction, calculate how far off the neural network was, and how to update the neural network, and then make the update.  \n",
    "\n",
    "Doing this 70,000 times will take some time (about 10 minutes).  And to keep even that efficient, you'll first need to go to the menu bar, followed by `runtime` and then `change runtime type`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <img src=\"./change_runtime_type.png\" width=\"30%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click on that, and then change the runtime type to GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <img src=\"./to_gpu.png\" width=\"40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that done, it's time to go train our neural network on the 70,000 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0554, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1444, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7173, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1364, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0828, grad_fn=<NllLossBackward>)\n",
      "tensor(2.5173, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1435, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1413, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "    for (x, y) in zip(x_train_tensor, y_train_tensor):\n",
    "        net.zero_grad()  \n",
    "        X_reshaped = x.view(-1,28*28)\n",
    "        prediction_batch = net(X_reshaped)\n",
    "        loss = x_loss(prediction_batch, y) \n",
    "        loss.backward() \n",
    "        adam.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating our Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get a sense of how our neural network performed.  First make  predictions on the first twenty observations in the testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = torch.tensor(x_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = net(x_test.view(-1, 28*28).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8848e-12, 2.2202e-16, 4.5645e-16, 1.6148e-15, 1.4248e-14, 4.9672e-02,\n",
       "         3.9909e-13, 7.0305e-01, 8.7145e-04, 2.4641e-01]],\n",
       "       grad_fn=<ExpBackward>)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(predictions_test[:1])\n",
    "\n",
    "# tensor([[4.4961e-08, 1.2412e-05, 4.5766e-09, 9.3961e-07, 1.2311e-06, 9.5997e-04,\n",
    "#          4.3604e-08, 4.5264e-03, 2.0135e-05, 9.9448e-01]],\n",
    "#        grad_fn=<ExpBackward>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_predictions = torch.argmax(predictions_test, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 2, 1, 1, 2, 1, 2, 2, 8, 7])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1, 1, 6, 1, 4, 6, 5, 7], dtype=uint8)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking good so far.  Next, check the accuracy of our neural network on our testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7022"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, hard_predictions)\n",
    "\n",
    "# 0.8303"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that our neural network identifies $.70$ of the data correctly.  Perhaps not perfect, but not too bad either."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we trained a neural network in Pytorch.  Nice work!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "[Colab Deeep Learning](https://colab.research.google.com/github/margaretmz/deep-learning/blob/master/fashion_mnist_keras.ipynb#scrollTo=d44TznbgZZgm)\n",
    "\n",
    "[Log Softmax](https://stats.stackexchange.com/questions/436766/cross-entropy-with-log-softmax-activation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
