{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building our Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last lesson, we saw how to work with and format our image data using Pytorch.  In this lesson, we'll work with our dataset of handwritten digits again, but this time feeding it into a neural network, and then using the neural network to identify some images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we'll need to download our data, which we can do so with the following line of code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: If trying to install keras on your laptop, run the following from the terminal:  `sudo pip3 install --upgrade --ignore-installed tensorflow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then let's make sure we still have our digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x144 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_, axes = plt.subplots(nrows=1, ncols=3, figsize=(6, 2))\n",
    "for ax, image, label in zip(axes, X_train, y_train):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can also make sure we have our corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now as we know, we'll have to convert this data into tensors and make sure the data is of type float, so let's take care of that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train).float()\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, as you may remember from the previous lesson, the next step will be to reshape our `X_tensor` data.  Let's better understand why we need to do that.  \n",
    "\n",
    "If we think about how we built a neural network in the past, our neural network consisted of a linear layer followed by an activation function, which we represented mathematically as the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$z(x) = w_1x_1 + w_2x_2 ... w_nx_n + b = w \\cdot x + b$\n",
    "\n",
    "$ \\sigma(z) = \\frac{1}{1 + e^{-z}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And focusing on that linear layer, remember that we have a separate weight for each feature in an observation.  So when working with image data, our feature are really the pixel values in of our 28x28 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is why we need to turn this 28x28 grid into one long list -- so that we can pass it as a vector to our linear function $z(x)$.  Ok, so let's reshape our our `X_train` tensor to be 60000 vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 784])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reshaped = X_tensor.view(60000, -1)\n",
    "\n",
    "X_reshaped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building our Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now previously, we built a relatively simple neural network, that consisted of one a linear layer, and an activation layer, and a single neuron.  We implemented it with the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=1, bias=True)\n",
       "  (1): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(2, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that, in the linear layer, the first number -- above 2 -- specified the number of input features per observation, and that the second argument -- above 1 -- specified the number of neurons.  \n",
    "\n",
    "> If we look at our linear layer, we'll see that this translates into a single vector of length 2, along with our bias term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              Parameter containing:\n",
       "              tensor([[0.4340, 0.6051]], requires_grad=True)),\n",
       "             ('bias',\n",
       "              Parameter containing:\n",
       "              tensor([-0.5125], requires_grad=True))])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0]._parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for our image data, we'll essentially need more of everything.  First, remember that each pixel in the image is treated as a separate feature.  So this means that our weight vectors should be of length $28x28 = 784$.  Also, instead of one neuron, we'll have 64 neurons.  And we'll also add additional layers of our neural network.\n",
    "\n",
    "> We'll see how these additional neurons, and layers can help us in the lessons that follow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=64, bias=True)\n",
       "  (1): Sigmoid()\n",
       "  (2): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(28*28, 64),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(64, 10)\n",
    ")\n",
    "\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Add in about layers and neurons here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we just created a neural network that will take in our tensors representing images.  Now before we train this neural network, let's make sure we undertand how it will predict what each image is.  We can see this by selecting our first image and passing it into our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_img = X_reshaped[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Remember that this is just one long tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_img[:150]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And when we pass it into our neural network, we get the following list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2774,  0.1835, -0.8635, -0.5925,  0.0163, -0.3360,  0.4016, -0.4791,\n",
       "         0.3488,  0.0700], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = net(first_img)\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so what is that?  Well, notice that our neural network returns a list of ten digits for a single picture.  This is because, it's predicting the likelihood that the photo matches any particular label.  We can see this even easier by passing our data through to Pytorch's softmax function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0818, 0.1296, 0.0455, 0.0597, 0.1097, 0.0771, 0.1612, 0.0668, 0.1529,\n",
       "        0.1157], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "F.softmax(pred, dim = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so now perhaps this can make more sense.  Each number in the list above represents the *likelihood* of the image being any particular digit.  So looking at the first two numbers above, our neural network predicted an $8.5%$ likelihood of the picture representing the digit $0$, and an $8.1$ percent of representing the digit $1$.  The index with the largest number is the predicted digit. \n",
    "\n",
    "> Here, the argmax function tells us that's 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that our neural network predicts that the first image is a 4.  In future lessons, we'll better understand this prediction function.  For now, let's move onto training the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we just used our neural network to make a prediction.  But we have not yet trained our neural network -- that is, we haven't yet taught our neural network how to recognize digits.  Let's do that now.  Remember that our procedure for training is the following:\n",
    "\n",
    "```python\n",
    "y_hat = net(X_tensor)             # 1. start with random weights and make the prediction\n",
    "loss = criterion(y_hat, y_tensor) # 2. See how off the prediction is according to the cost function\n",
    "loss.backward()                   # 3a. Calculate the slope of the cost curve at that weight\n",
    "opt.step()                        # 4. Update the parameters based on the learning rate and the calculated slope \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So once again, we are repeatedly updating our weights to descend along our cost curve, to find the ideal weights for our neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's start.  As we know, we'll need our *loss function*, which will evaluate how far off each prediction is.  And we'll need our optimizer, which is where we'll specify our learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "x_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "adam = optim.Adam(net.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now it's time to go through our three steps for training the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Predict the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2774,  0.1835, -0.8635, -0.5925,  0.0163, -0.3360,  0.4016, -0.4791,\n",
       "          0.3488,  0.0700]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = net(X_reshaped[:1])\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Calculate the loss (by comparing the prediction with the label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_label = y_train_tensor[:1]\n",
    "first_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5626, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = x_loss(pred, first_label)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Update the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To update the neural network, we call two functions.  The backward function calculates *how* to update the neural network, and the step function actually makes the updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()\n",
    "adam.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so that's how we train our neural network on a single image.  Now we just need to loop through each of our images following the training steps that we just saw: \n",
    "\n",
    "1. Have our neural network make a prediction, \n",
    "2. Calculate how far off the prediction is\n",
    "3. Determine how to update the neural network and \n",
    "4. Make the update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so it's time to train on all of our images.  \n",
    "\n",
    "Doing this will take some time (about 10 minutes) -- but it will take a lot longer, if we do not first switch to having colab use the GPU (which is faster than the CPU it's currently using).  To make the switch, you'll first need to go to the menu bar and click on `runtime` and then click on `change runtime type`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <img src=\"./change_runtime_type.png\" width=\"30%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From there, change the runtime type to GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <img src=\"./to_gpu.png\" width=\"40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now let's go through the steps of creating a neural network, and then training it.  We create our neural network with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then call the `cuda` function so that this runs on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we also need the training data and labels to run on the GPU, so we call cuda on them as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor_gpu = X_train_tensor.cuda()\n",
    "\n",
    "y_train_tensor_gpu = y_train_tensor.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's reinitializer our loss function, and the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "x_loss = nn.CrossEntropyLoss()\n",
    "adam = optim.Adam(net.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, let's loop through the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0554, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1444, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7173, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1364, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0828, grad_fn=<NllLossBackward>)\n",
      "tensor(2.5173, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1435, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1413, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "    for (x, y) in zip(x_train_tensor_gpu, y_train_tensor_gpu):\n",
    "        net.zero_grad()  \n",
    "        X_reshaped = x.view(-1,28*28) # change image from grid to a list\n",
    "        prediction = net(X_reshaped) # make prediction\n",
    "        loss = x_loss(prediction, y) # calculate loss\n",
    "        loss.backward() # determine how to update the neural network\n",
    "        adam.step() # make the update\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating our Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so to see how good of a job our neural network does at evaluating images, we don't want to use the same images we used to train our neural network -- our neural network has already seen these, as well as the answers.  Instead, we want to see how well our neural network performs on some images that it hasn't yet seen.  \n",
    "These are the images in our test set, which we downloaded when we downloaded our dataset.  To use the data in our test set, we first need to convert `X_test` into a tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_gpu = torch.tensor(X_test).view(-1, 28*28).float().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we can see how well it performed with the first image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = net(X_test_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8848e-12, 2.2202e-16, 4.5645e-16, 1.6148e-15, 1.4248e-14, 4.9672e-02,\n",
       "         3.9909e-13, 7.0305e-01, 8.7145e-04, 2.4641e-01]],\n",
       "       grad_fn=<ExpBackward>)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(predictions_test[:1], dim = 1)\n",
    "\n",
    "# 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which looks like a good prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10f702dc0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we can get the predictions for the entire test set by passing the predictions into the `argmax` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_predictions = torch.argmax(predictions_test, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can eyeball how well our first predictions match up with the labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 2, 1, 1, 2, 1, 2, 2, 8, 7])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1, 1, 6, 1, 4, 6, 5, 7], dtype=uint8)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking good so far.  Next, let's check the accuracy of our neural network on our testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, hard_predictions.cpu())\n",
    "\n",
    "# 0.8881"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that our neural network identifies $.89$ of the data correctly.  Not too bad for our first neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we trained a neural network in Pytorch.  Nice work!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "[Colab Deeep Learning](https://colab.research.google.com/github/margaretmz/deep-learning/blob/master/fashion_mnist_keras.ipynb#scrollTo=d44TznbgZZgm)\n",
    "\n",
    "[Log Softmax](https://stats.stackexchange.com/questions/436766/cross-entropy-with-log-softmax-activation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
