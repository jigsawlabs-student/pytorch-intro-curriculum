{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building our Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last lesson, we saw some of the data that neural networks could interpret, and did so exploring our dataset of handwritten digits.  In this lesson, we'll work with that dataset again, this time feeding it into a neural network, and then using the neural network to identify some images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we'll need to download our data, which we can do so with the following line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then let's make sure we still have our digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x144 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_, axes = plt.subplots(nrows=1, ncols=3, figsize=(6, 2))\n",
    "for ax, image, label in zip(axes, X_train, y_train):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we have our corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, cool so far so good.  Let's move onto building our neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building our Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build our neural network, we'll use the Pytorch library.  There's no way we can understand the ins and outs of a neural network just in this lesson.  Instead, let's just see it action for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by importing the Pytorch library, and then can build a neural network class with the following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Press `shift + return` on the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(0)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.W1 = nn.Linear(28*28, 64)\n",
    "        self.W2 = nn.Linear(64, 64)\n",
    "        self.W3 = nn.Linear(64, 64)\n",
    "        self.W4 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        A1 = w(self.W1(X))\n",
    "        A2 = torch.sigmoid(self.W2(A1))\n",
    "        A3 = torch.sigmoid(self.W3(A2))\n",
    "        Z4 = self.W4(A3)\n",
    "        return Z4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So above, we defined a *class* that creates neural networks.  A **class** is a programming concept.  If you're not familiar with term, just know that in the lines above we essentially created a factory that now can produce neural networks for us.  Want to build a neural network?  We just need to call on our factory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so now that we created our class for building neural networks, and created a neural network, assigning it to the variable `net`, let's start training the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now remember that *training* our neural network means that we'll feed our neural network our input data, and the corresponding labels.  This should make sense.  When we called `net = Net()`, we just built a neural network fresh out of the factory.  So while it has the capacity to learn how to identify images -- it hasn't undergone it's training process yet.\n",
    "\n",
    "When we train our neural network, we take our picture, have our neural network predict which digit it is, and then we check if the prediction was correct -- and update our neural network if the prediction was wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's focus on the prediction step. To pass our data into a neural network, Pytorch first requires us to change our `X_train`, and `y_train` data from a numpy array, to a tensor.  \n",
    "\n",
    "> Our data starts off as numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train), type(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> And we convert them to the Pytorch equivalent of tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train).float()\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train).long().view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Tensor)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_tensor), type(y_train_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now that our data is converted we can select our first image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_image = X_train_tensor[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're almost good to go, but the last step is that when we pass our data into the neural network, we need to change it from a grid, how it starts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_image[:][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To one long list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "coerced_obs = first_image.view(-1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coerced_obs[0][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We'll discuss the `view` function in more detail later on.  But notice that our first observation has been changed to a list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now that we (1) changed our data from numpy arrays to tensors and (2) changed our first photo from a grid to a list we can simply pass it into our neural network, and out will come a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0677, -0.1086,  0.1979,  0.3088,  0.5144,  0.0892, -0.4978, -0.0069,\n",
       "          0.1117,  0.1407]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = net(coerced_obs)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now we have our prediction, but how are we supposed to interpret it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now let's better understand that prediction above.  First, notice that our neural network returns a list of ten digits for a single picture.  This is because, it's predicting the likelihood that the photo matches any particular label.  We can see this even easier by passing our data through to Pytorch's softmax function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0846, 0.0812, 0.1103, 0.1233, 0.1514, 0.0990, 0.0550, 0.0899, 0.1012,\n",
       "         0.1042]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(pred, dim = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so now perhaps this can make more sense.  Each number in the list above represents the likelihood of the image being any particular digit.  So looking at the first two numbers above, our neural network predicted an $8.5%$ likelihood of the picture representing the digit $0$, and an $8.1$ percent of representing the digit $1$.  The index with the largest number is the predicted digit. \n",
    "\n",
    "> Here, the argmax function tells us that's 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that our neural network predicts that the first image is a 4.  In future lessons, we'll better understand this prediction function.  For now, let's move onto training the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we just used our neural network to make a prediction.  But we have not yet trained our neural network -- that is, we haven't yet taught our neural network how to recognize digits.  Let's do that now.  Remember that our procedure for training is the following:\n",
    "\n",
    "1. Have the neural network **predict the output**\n",
    "2. **Calculate the loss** -- that is calculate how far off the prediction is from the answer (indicated by the label).\n",
    "3. **Update the neural** network to ideally improve it's predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, to calculate the loss and then update the neural network -- we'll need two more tools: our loss function, and our optimizer, which updates the neural network.  We create them below.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "x_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "adam = optim.Adam(net.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now it's time to go through our three steps for training the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Predict the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0677, -0.1086,  0.1979,  0.3088,  0.5144,  0.0892, -0.4978, -0.0069,\n",
       "          0.1117,  0.1407]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = net(coerced_obs)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Calculate the loss (by comparing the prediction with the label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_label = y_train_tensor[0]\n",
    "first_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3131, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = x_loss(pred, first_label)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Update the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To update the neural network, we call two functions.  The backward function calculates *how* to update the neural network, and the step function actually makes the updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()\n",
    "adam.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so that's how we train our neural network on a single image.  Now we just need to loop through each of our images following the training steps that we just saw: \n",
    "\n",
    "1. Have our neural network make a prediction, \n",
    "2. Calculate how far off the prediction is\n",
    "3. Determine how to update the neural network and \n",
    "4. Make the update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so it's time to train on all of our images.  \n",
    "\n",
    "Doing this will take some time (about 10 minutes) -- but it will take a lot longer, if we do not first switch to having colab use the GPU (which is faster than the CPU it's currently using).  To make the switch, you'll first need to go to the menu bar and click on `runtime` and then click on `change runtime type`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <img src=\"./change_runtime_type.png\" width=\"30%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From there, change the runtime type to GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <img src=\"./to_gpu.png\" width=\"40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now let's go through the steps of creating a neural network, and then training it.  We create our neural network with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then call the `cuda` function so that this runs on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we also need the training data and labels to run on the GPU, so we call cuda on them as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor_gpu = X_train_tensor.cuda()\n",
    "\n",
    "y_train_tensor_gpu = y_train_tensor.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's reinitializer our loss function, and the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "x_loss = nn.CrossEntropyLoss()\n",
    "adam = optim.Adam(net.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, let's loop through the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0554, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1444, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7173, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1364, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0828, grad_fn=<NllLossBackward>)\n",
      "tensor(2.5173, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1435, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1413, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "    for (x, y) in zip(x_train_tensor_gpu, y_train_tensor_gpu):\n",
    "        net.zero_grad()  \n",
    "        X_reshaped = x.view(-1,28*28) # change image from grid to a list\n",
    "        prediction = net(X_reshaped) # make prediction\n",
    "        loss = x_loss(prediction, y) # calculate loss\n",
    "        loss.backward() # determine how to update the neural network\n",
    "        adam.step() # make the update\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some more knowledge while we wait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now above, our neural network is cycling through all of our images.  In fact, that `for epoch in range(3)` in the code above means that really, it is cycling through each of the images three times.  And of course with each image we have the neural network predict the label, calculating how far off the prediction is, calculating how to update the neural network, and then finally making the update.\n",
    "\n",
    "Now let's go a little deeper into what it means to *calculate how far off the prediction is*, and what it means to *update the neural network*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Calculating how far off the prediction is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that when we make a prediction, we actually get 10 different numbers -- one for each of the potential digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0546, 0.1164, 0.1456, 0.1033, 0.0754, 0.1067, 0.1067, 0.0686, 0.1011,\n",
       "         0.1217]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = net(coerced_obs)\n",
    "F.softmax(pred, dim = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And these numbers indicate the predicted likelihood that the picture is a each particular digit.  And then if we look at the actual label, we see that it is the number 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the closer the fifth index in the prediction is to the number 1 the better the prediction.  Or in machine learning terms, the lower the loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2381, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_loss(pred, first_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's hard to interpret that loss above, but notice the loss decreases if the prediction is close the actual label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4619)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt_pred = torch.tensor([[0, 0, 0, 0, 0, .999, 0, 0, 0, 0]])\n",
    "\n",
    "x_loss(alt_pred, first_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> See?  We raised the number at the fifth index, passed through a matching label of 5, and the loss went down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Understanding updating the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now that we better understand what it means to calculate *how far off the neural network is*, next let's better understand what it means to update the neural network.  Take another look at the last three steps in our training loop:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "for (x, y) in zip(x_train_tensor, y_train_tensor):\n",
    "        net.zero_grad()  \n",
    "        X_reshaped = x.view(-1,28*28) # change image from grid to a list\n",
    "        \n",
    "        # FOCUS on the lines below\n",
    "        prediction = net(X_reshaped) # make prediction\n",
    "        loss = x_loss(prediction, y) # calculate loss\n",
    "        loss.backward() # determine how to update the neural network\n",
    "        adam.step() # make the update\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that after we make the prediction, and then calculate the loss, we then call `loss.backward()` and `adam.step()` -- so this determines how to update the neural network, and then makes the update.\n",
    "\n",
    "What does it mean to update the neural network?  Well let's take another look at the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "net\n",
    "\n",
    "# Net(\n",
    "#   (W1): Linear(in_features=784, out_features=64, bias=True)\n",
    "#   (W2): Linear(in_features=64, out_features=64, bias=True)\n",
    "#   (W3): Linear(in_features=64, out_features=64, bias=True)\n",
    "#   (W4): Linear(in_features=64, out_features=10, bias=True)\n",
    "# )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of those `W's` stand for weights -- and the neural network takes those weights and combined with the input of the numbers in our picture to get an output.  Let's take a look at just one of the weights, $W3$.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              Parameter containing:\n",
       "              tensor([[-0.1107,  0.0709,  0.0197,  ..., -0.0999,  0.0677, -0.0148],\n",
       "                      [ 0.0819, -0.0584, -0.0949,  ...,  0.0427,  0.0739,  0.0413],\n",
       "                      [ 0.1190, -0.0815, -0.0119,  ..., -0.0239,  0.0813,  0.0625],\n",
       "                      ...,\n",
       "                      [-0.0990, -0.0215,  0.1097,  ...,  0.1177, -0.0939,  0.0936],\n",
       "                      [-0.0224,  0.1201,  0.0708,  ...,  0.0910,  0.1074,  0.1040],\n",
       "                      [-0.1047,  0.0481, -0.0585,  ...,  0.0946, -0.1072,  0.0667]],\n",
       "                     requires_grad=True)),\n",
       "             ('bias',\n",
       "              Parameter containing:\n",
       "              tensor([ 0.0919,  0.0518,  0.0656,  0.0216,  0.0790, -0.0235,  0.0004,  0.1122,\n",
       "                       0.0241,  0.0005,  0.0535,  0.0059, -0.0718, -0.0968,  0.0081,  0.0295,\n",
       "                      -0.1138,  0.0205,  0.1031,  0.0367,  0.1164,  0.0291, -0.1202,  0.0127,\n",
       "                      -0.0725, -0.0426, -0.0469,  0.0549, -0.0484,  0.0367,  0.0270,  0.1153,\n",
       "                       0.0021,  0.0853,  0.0872, -0.0785,  0.0463, -0.0082, -0.1213,  0.1200,\n",
       "                      -0.0268,  0.1231,  0.0309, -0.0771, -0.0370, -0.0153, -0.1130,  0.0197,\n",
       "                       0.0244,  0.1073,  0.1101, -0.0167,  0.0705, -0.0035, -0.1126, -0.0518,\n",
       "                      -0.0694,  0.0965, -0.0466, -0.0293, -0.0376,  0.0287,  0.0903,  0.0420],\n",
       "                     requires_grad=True))])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.W3._parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The point is that there are a lot of numbers.  And this is just one of the four W's.  When we call `loss.backward()`, Pytorch calculates *how* to update each of these weights across all four layers, and then with `adam.step()` it actually updates these numbers.  Perhaps we can see why we first needed to calculate the how far off our prediction was -- the further off the prediction, the larger the update.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now understanding how all of these numbers combine to turn into a prediction, and how the neural network determines how to update all of these numbers above, is important to understanding neural networks -- and machine learning.  So this is what future lessons will focus on.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, by now, our neural network may be just about finished training.  If you see that the tab for colab has changed back from gray to yellow, then the neural network has finished training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <img src=\"./yellow_tab.png\" width=\"30%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's now see how well our neural network predicts each image's corresponding digit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating our Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so to see how good of a job our neural network does at evaluating images, we don't want to use the same images we used to train our neural network -- our neural network has already seen these, as well as the answers.  Instead, we want to see how well our neural network performs on some images that it hasn't yet seen.  \n",
    "These are the images in our test set, which we downloaded when we downloaded our dataset.  To use the data in our test set, we first need to convert `X_test` into a tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_gpu = torch.tensor(X_test).view(-1, 28*28).float().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we can see how well it performed with the first image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = net(X_test_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8848e-12, 2.2202e-16, 4.5645e-16, 1.6148e-15, 1.4248e-14, 4.9672e-02,\n",
       "         3.9909e-13, 7.0305e-01, 8.7145e-04, 2.4641e-01]],\n",
       "       grad_fn=<ExpBackward>)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(predictions_test[:1], dim = 1)\n",
    "\n",
    "# 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which looks like a good prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10f702dc0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we can get the predictions for the entire test set by passing the predictions into the `argmax` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_predictions = torch.argmax(predictions_test, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can eyeball how well our first predictions match up with the labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 2, 1, 1, 2, 1, 2, 2, 8, 7])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1, 1, 6, 1, 4, 6, 5, 7], dtype=uint8)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking good so far.  Next, let's check the accuracy of our neural network on our testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, hard_predictions.cpu())\n",
    "\n",
    "# 0.8881"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that our neural network identifies $.89$ of the data correctly.  Not too bad for our first neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we trained a neural network in Pytorch.  Nice work!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "[Colab Deeep Learning](https://colab.research.google.com/github/margaretmz/deep-learning/blob/master/fashion_mnist_keras.ipynb#scrollTo=d44TznbgZZgm)\n",
    "\n",
    "[Log Softmax](https://stats.stackexchange.com/questions/436766/cross-entropy-with-log-softmax-activation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
