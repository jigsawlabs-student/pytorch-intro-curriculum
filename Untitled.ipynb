{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "previous-cemetery",
   "metadata": {},
   "source": [
    "### Extra on Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-committee",
   "metadata": {},
   "source": [
    "Remember that with training, we first have our neural network make a prediction, like we did above.\n",
    "\n",
    "in training we'll do the following.  We'll take our set of images, and for each image, we'll input it into our neural network, have the neural network make a prediction, and then update the neural network based on how off the prediction was.  So if the neural network said there was a $.05$ percent chance of the picture being a hat, but the picture was in fact a hat -- the neural network will be updated a lot, and if it predicted a $.95$ percent chance of our hat being a hat, then we would not update our neural network so much.\n",
    "\n",
    "What does it mean to update a neural network?  Well let's take a look at our neural network again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-cabin",
   "metadata": {},
   "source": [
    "So we can see that our neural network predicts that the first image is what's at image 4 -- or a coat.  In future lessons, we'll better understand this prediction function.  For now, let's move onto training the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "conditional-wrapping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (W1): Linear(in_features=784, out_features=64, bias=True)\n",
       "  (W2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (W3): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (W4): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faced-suspect",
   "metadata": {},
   "source": [
    "Each one of those `W's` represents a grid of numbers.  Let's see one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "metric-maria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              Parameter containing:\n",
       "              tensor([[ 0.0259, -0.0138, -0.0259,  ..., -0.0757, -0.0621, -0.0298],\n",
       "                      [ 0.1063,  0.0534, -0.0855,  ..., -0.0165, -0.0313, -0.0833],\n",
       "                      [ 0.1078,  0.0445,  0.0239,  ..., -0.0503,  0.0975, -0.0178],\n",
       "                      ...,\n",
       "                      [ 0.1124,  0.0989, -0.0902,  ..., -0.0939, -0.0652,  0.1107],\n",
       "                      [ 0.1120, -0.0405,  0.0659,  ..., -0.0038, -0.0218, -0.0882],\n",
       "                      [ 0.1226,  0.0628, -0.0597,  ..., -0.0875,  0.0712,  0.1169]],\n",
       "                     requires_grad=True)),\n",
       "             ('bias',\n",
       "              Parameter containing:\n",
       "              tensor([-0.0495,  0.0637, -0.1004, -0.0250, -0.0909,  0.1096,  0.0405,  0.0485,\n",
       "                       0.0361, -0.1112,  0.0071,  0.0476,  0.1005,  0.0198, -0.0114,  0.0470,\n",
       "                      -0.0566, -0.0448,  0.0945, -0.0279, -0.0823,  0.1084,  0.1233,  0.1245,\n",
       "                      -0.0628, -0.1026,  0.0119,  0.1122, -0.1189,  0.1191, -0.0267, -0.0029,\n",
       "                      -0.0684,  0.0300, -0.0023, -0.0248,  0.0255,  0.0204,  0.0377, -0.0720,\n",
       "                       0.1083,  0.1226,  0.1195, -0.0623,  0.1184, -0.0169,  0.0962,  0.0845,\n",
       "                       0.0651, -0.1006, -0.0409,  0.0330, -0.0726, -0.0220,  0.0756, -0.1135,\n",
       "                       0.0116,  0.0716, -0.1130, -0.0081, -0.0813, -0.0165,  0.1023, -0.0797],\n",
       "                     requires_grad=True))])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.W3._parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unique-abraham",
   "metadata": {},
   "source": [
    "That's a lot of numbers.  \n",
    "\n",
    "> And remember, these are just the numbers that consist of one of those `W's`.  There are four of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-argentina",
   "metadata": {},
   "source": [
    "Depending on how far off the neural network's ultimate prediction is, those numbers will be updated with each prediction the neural network sees.  \n",
    "\n",
    "It takes a little bit of setup to go through this, but still let's see it in action."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-concentration",
   "metadata": {},
   "source": [
    "> We use something called cross entropy loss, and an optimizer -- both oof which we'll learn more about later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "leading-ecology",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_loss = nn.CrossEntropyLoss()\n",
    "x_loss\n",
    "# CrossEntropyLoss()\n",
    "\n",
    "import torch.optim as optim\n",
    "adam = optim.Adam(net.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minimal-tutorial",
   "metadata": {},
   "source": [
    "And then if we pass through the neural network's *prediction*, and the corresponding label, we can see how far off we were."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "confirmed-airline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2632, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = net(first_obs)\n",
    "pred\n",
    "\n",
    "first_label = y_train_tensor[0]\n",
    "first_label\n",
    "\n",
    "loss = x_loss(pred, first_label)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-apparatus",
   "metadata": {},
   "source": [
    "Then we can calculate how to update our neural network, and finally, make the update with the `step` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "registered-cassette",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()\n",
    "adam.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-consultancy",
   "metadata": {},
   "source": [
    "With that our neural network has been updated, just a little bit, based on it's poor prediction of the first image.  Let's see this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-wisdom",
   "metadata": {},
   "source": [
    "> Notice that the first number was updated from $.0259$ to $.03$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "promising-worst",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              Parameter containing:\n",
       "              tensor([[ 0.0309, -0.0088, -0.0209,  ..., -0.0707, -0.0571, -0.0248],\n",
       "                      [ 0.1013,  0.0484, -0.0905,  ..., -0.0215, -0.0363, -0.0883],\n",
       "                      [ 0.1128,  0.0495,  0.0289,  ..., -0.0453,  0.1025, -0.0128],\n",
       "                      ...,\n",
       "                      [ 0.1174,  0.1039, -0.0852,  ..., -0.0889, -0.0602,  0.1157],\n",
       "                      [ 0.1170, -0.0355,  0.0709,  ...,  0.0012, -0.0168, -0.0832],\n",
       "                      [ 0.1276,  0.0678, -0.0547,  ..., -0.0825,  0.0762,  0.1219]],\n",
       "                     requires_grad=True)),\n",
       "             ('bias',\n",
       "              Parameter containing:\n",
       "              tensor([-0.0445,  0.0587, -0.0954, -0.0200, -0.0859,  0.1046,  0.0355,  0.0435,\n",
       "                       0.0411, -0.1062,  0.0021,  0.0426,  0.1055,  0.0148, -0.0164,  0.0420,\n",
       "                      -0.0616, -0.0398,  0.0995, -0.0329, -0.0773,  0.1134,  0.1283,  0.1295,\n",
       "                      -0.0678, -0.1076,  0.0169,  0.1072, -0.1239,  0.1241, -0.0217,  0.0021,\n",
       "                      -0.0634,  0.0350, -0.0073, -0.0298,  0.0205,  0.0154,  0.0427, -0.0670,\n",
       "                       0.1133,  0.1176,  0.1145, -0.0673,  0.1134, -0.0219,  0.0912,  0.0895,\n",
       "                       0.0701, -0.0956, -0.0459,  0.0380, -0.0676, -0.0270,  0.0806, -0.1185,\n",
       "                       0.0166,  0.0666, -0.1080, -0.0131, -0.0863, -0.0115,  0.1073, -0.0747],\n",
       "                     requires_grad=True))])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.W3._parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
