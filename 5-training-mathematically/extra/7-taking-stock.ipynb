{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taking Stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have learned a lot of the content needed to train a single neuron.  As we'll see, our technique of using gradient descent to find the parameters of a hypothesis function is a large part of how we'll train an entire neural network. \n",
    "\n",
    "Let's take a moment to recap what we've learned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw that we can think of the hypothesis function for our neuron as two components, a linear component and an activation function.  We could even think of this as occurring in a layers, where we first feed our inputs into our linear component $z(x)$, which produces an output that is fed into the activation function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $z(x) = w_1x_1 + w_2x_2 + ... w_nx_n + b$\n",
    "* $a(z) = \\frac{1}{1 + e^{-z}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our linear function $z(x)$ produces an output between positive and negative infinity, and our activation function, the sigmoid function, maps this to values between 0 and 1.  The output from our activation function expresses a degree of confidence in the prediction.  For example, the closer the output is to zero, the more confident the hypothesis function is that the observation has a value of 0.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Our Hypothesis Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then moved into training our hypothesis function for a neuron.  That is, we spoke about the procedure for finding the parameters of our hypothesis function.  \n",
    "\n",
    "This procedure was gradient descent, which we described as initializing a parameter at a random value, and then repeatedly updating the parameter according to the formula:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\theta_{next} = \\theta_{current} -\\eta*slope\\_at(\\theta_{current})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or in code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "weight = -2\n",
    "learning_rate = .01\n",
    "for idx in range(0, 10):\n",
    "    weight =  weight - learning_rate*sse_slope(weight)\n",
    "weight\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the Rate of Change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then described how we can calculate this slope.  The slope of a function at a specific value is equal to the derivative of the function at that value.  The derivative of our function, is the instantaneous rate of change of our function, or:   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\delta y}{\\delta x} = lim_{\\delta x\\to0}\\frac{y_1 - y_0}{x_1 - x_0}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And using the derivative in gradient descent, calculating the derivative means calculating the instantaneous rate of change in our cost function, with respect to our parameter.  In other words, as we nudge a parameter, how much does our cost function change.  If our cost function changes a lot, then we are not close to the minimum and should move the parameter a lot to descend along the cost curve.\n",
    "\n",
    "We updated our gradient descent formula to use the derivative notation, and letting $J$ equal our cost function so that:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\theta_{next} = \\theta_{current} -\\eta*J'(\\theta_{current})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\theta_{next} = \\theta_{current} -\\eta*\\frac{\\delta J}{\n",
    "\\delta \\theta}(\\theta_{current})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where $\\theta$ represents any parameter, in previous lessons a weight $w$, and $\\eta$ is the learning rate, which is just a small number like .01."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving to two parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After seeing how we could use gradient descent to find the parameters of a hypothesis function where there is only one parameter, we then moved onto seeing how we could use gradient descent with two parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With two parameters, our cost curve is now in three dimensions.  And we are seeing how much to update each parameter.  We did this by finding the partial derivative with respect to each parameter.  In other words, we calculate the instantaneous rate of change in the cost function with respect to one parameter -- while holding all others constant, and then with respect to the next parameter while holding all others constant.\n",
    "\n",
    "We update the parameter in proportion to how much changing them reduces the output of the cost function.  That is, we update our parameters so that we get the most bang for our buck."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "w = .5\n",
    "b = .5\n",
    "eta = .01\n",
    "\n",
    "for i in range(0, 150):\n",
    "    for (x, y) in paired_data:\n",
    "        dj_dw_calc = dj_dw(w, b, x, y)\n",
    "        dj_db_calc = dj_db(w, b, x, y)\n",
    "        w += -eta*dj_dw_calc\n",
    "        b += -eta*dj_db_calc\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By following that procedure, we saw how we can find the parameters that produce the lowest output of our cost function.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving Forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So over the last several lessons, we learned about both the our hypothesis function and the training procedure for a single neuron.  There is one component that we left out, something about the chain rule.  So, we'll close by learning about how using the chain rule can allow us to find the parameters for an entire neural network, through something called back propagation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"https://www.jigsawlabs.io/free\" style=\"position: center\"><img src=\"jigsaw-icon.png\" width=\"15%\" style=\"text-align: center\"></a>\n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
